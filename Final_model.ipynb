{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change file locations scroll down and see at the start of main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7565b",
   "metadata": {},
   "source": [
    "Preparation by defining my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_parquet_csv(test_path, submission_path, train_path):\n",
    "    train_df = pd.read_parquet(train_path)\n",
    "    test_df = pd.read_parquet(test_path)\n",
    "    sample_submission_df = pd.read_csv(submission_path)\n",
    "    return train_df, test_df, sample_submission_df\n",
    "\n",
    "def prepare_imputation_data(test_df, timestamp_col='timestamp'):\n",
    "    \"\"\"Drop timestamp for imputation, return data and timestamp separately.\"\"\"\n",
    "    imputation_df = test_df.drop(columns=[timestamp_col])\n",
    "    timestamp = test_df[timestamp_col]\n",
    "    return imputation_df, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extra_trees_imputer():\n",
    "    estimator = ExtraTreesRegressor(\n",
    "        n_estimators=300,\n",
    "        criterion='squared_error',\n",
    "        max_depth=30,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        max_features=0.8,\n",
    "        max_leaf_nodes=None,\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        warm_start=False,\n",
    "        max_samples=None\n",
    "    )\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=estimator,\n",
    "        missing_values=float(\"nan\"),\n",
    "        sample_posterior=False,\n",
    "        max_iter=10,\n",
    "        tol=0,\n",
    "        n_nearest_features=None,\n",
    "        initial_strategy='mean',\n",
    "        imputation_order='roman',\n",
    "        skip_complete=True,\n",
    "        verbose=2,\n",
    "        random_state=99,\n",
    "        add_indicator=False\n",
    "    )\n",
    "    return imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9322744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I do know that by keeping tol=0, I need to use very high number of\n",
    "# iterations to converge but Increasing max_iter to a larger number\n",
    "# I was not able to run on my pc so I just let it be 10 and still \n",
    "# tried to keep tol=0 which has given me decent improvement in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(imputer, data_to_impute):\n",
    "    print(\"Starting imputation...\")\n",
    "    imputed_array = imputer.fit_transform(data_to_impute)\n",
    "    print(\"Imputation completed.\")\n",
    "    return imputed_array\n",
    "\n",
    "def reconstruct_imputed_df(imputed_array, impute_columns, timestamp):\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=impute_columns)\n",
    "    imputed_df['timestamp'] = timestamp.values\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae435f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_to_submission_columns(imputed_df, sample_submission_df):\n",
    "    # Keep only columns present in sample_submission, in the same order\n",
    "    common_cols = [col for col in sample_submission_df.columns if col in imputed_df.columns]\n",
    "    filtered_df = imputed_df[common_cols]\n",
    "    return filtered_df\n",
    "\n",
    "def save_final_submission(filtered_df, output_path):\n",
    "    filtered_df.to_csv(output_path, index=False)\n",
    "    print(f\"Final submission saved to '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56c906",
   "metadata": {},
   "source": [
    "MAIN EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train_data.parquet'\n",
    "TEST_PATH = 'test_data.parquet'\n",
    "SUBMISSION_PATH = 'sample_submission.csv'\n",
    "OUTPUT_PATH = 'final_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214faf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data (test and train as parquet, sample submission as CSV)\n",
    "train_df, test_df, sample_submission_df = load_data_parquet_csv(TEST_PATH, SUBMISSION_PATH, TRAIN_PATH)\n",
    "\n",
    "# 2. Prepare data for imputation\n",
    "imputation_df, timestamp = prepare_imputation_data(test_df, timestamp_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db885242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build and fit imputer\n",
    "imputer = build_extra_trees_imputer()\n",
    "imputed_array = impute_data(imputer, imputation_df)\n",
    "\n",
    "# 4. Reconstruct imputed DataFrame with timestamp\n",
    "imputed_df = reconstruct_imputed_df(imputed_array, imputation_df.columns, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f56d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Filter columns to match sample submission\n",
    "filtered_df = filter_to_submission_columns(imputed_df, sample_submission_df)\n",
    "\n",
    "# 6. Save final submission as CSV\n",
    "save_final_submission(filtered_df, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39057a75",
   "metadata": {},
   "source": [
    "This saved file is my best submission"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
